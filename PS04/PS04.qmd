---
title: "Problem Set 3"
author: "Brynn Woolley"
format:
  pdf:
    include-in-header:
      text: |
        \usepackage{amsmath}
editor: visual
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE)

library(dplyr)
library(readr)
library(ggplot2)
library(tidyr)
library(stringr)
library(broom)
```

## Problem 1 
<!-- 
This problem will require you to learn things we have not covered. Use the R help, or online resources, to figure out the appropriate command(s). Use citation as necessary.  

For the “nice tables”, use a function such as `kable` from knitr, or the stargazer package (or find another approach) to generate HTML/LaTeX tables for inclusion. The results should be clearly labeled, rounded appropriately, and easily readable.  

-->
a. Download the file AUX_I from [this location](https://wwwn.cdc.gov/Nchs/Nhanes/2017-2018/AUX_I.htm), and determine how to read it into R. Then download the file DEMO_I from [this location](https://wwwn.cdc.gov/Nchs/Nhanes/2017-2018/DEMO_I.htm). Note that each page contains a link to a documentation file for that data set. Merge the two files to create a single `data.frame`. Keep only records which matched. Print out the dimensions of the merged `data.frame`.  


```{r}

```
b. We’ll be using the following variables. Clean up each - ensure all missing values are actually `NA` (rather than `999` or something), and if it’s categorical, convert it to `factor` with informative `levels`.  
   * Gender  
   * Citizenship status  
   * Number of children 5 years or younger in the household  
   * Annual household income - There’s also an issue with the ordering of the categories here; take a look, identify the issue, and implement a solution.  
```{r}

```

c. The Tympanometric width measure is looks approximately like a Poisson distribution. Fit four Poisson regression models predicting a respondent’s Tympanometric width in each ear. Each model is defined below, for a specific ear and a specific set of covariates.  
   * 1R - Right ear: gender  
   * 2R - Right ear: gender, citizenship status (as categorical), number of children (as continuous), annual household income (as continuous)  
   * 1L - Left ear: gender  
   * 2L - Left ear: gender, citizenship status (as categorical), number of children (as continuous), annual household income (as continuous)  

Produce a table presenting the estimated incidence risk ratios for the coefficients in each model, along with the sample size for the model, the pseudo-\(R^2\), and AIC values. (This can be a single table, or one table for coefficients and a separate table for model statistics).  

The table(s) should be “nice” - use a function such as `kable` from knitr, or the stargazer package (or find another approach) to generate HTML/LaTeX tables for inclusion. The results should be clearly labeled, rounded appropriately, and easily readable.  

```{r}

```

d. From model 2L, provide evidence whether there is a difference between males and females in terms of their incidence risk ratio. Test whether the predicted value of Tympanometric width measure of the left ear differs between men and women. Include the results of the each test and their interpretation.  

```{r}

```
## Problem 2 - Sakila  

Use the “sakila” database discussed in class. It can be downloaded from [https://github.com/bradleygrant/sakila-sqlite3](https://github.com/bradleygrant/sakila-sqlite3).  

For these problems, do not use any of the tables whose names end in `_list`.  

For each of the following questions, solve them in two ways: First, use SQL query or queries to extract the appropriate table(s), then use regular R operations on those `data.frame`s to answer the question. Second, use a single SQL query to answer the question. Compare each approach using microbenchmark.  

a. For each store, how many customers does that store have, and what percentage of customers of that store are active in the system?  

```{r}

```

b. Generate a table identifying the names and country of each staff member.  

```{r}

```

c. Identify the name(s) of the film(s) which was/were rented for the highest dollar value. (Assume all costs are in USD regardless of country.) (Hint: You can merge a table more than once.)  

```{r}

```
## Problem 3 - Australian Records 

Download the “Australia - 500 Records” data from [https://www.briandunning.com/sample-data/](https://www.briandunning.com/sample-data/) and import it into R. This is entirely fake data; you can read the website for details. Use it to answer the following questions.  

a. What percentage of the websites are .com’s (as opposed to .net, .com.au, etc)?  

```{r}


```

b. What is the most common domain name amongst the email addresses? (In the email “statistics@umich.edu”, “umich.edu” is the domain name.)  
```{r}


```

c. What proportion of company names contain a non-alphabetic character, excluding commas and whitespace. (E.g. “Jane Doe, LLC” would not contain an eligible non-alphabetic character; “Plumber 247” would.) What about if you also exclude ampersands (“&”)?  

```{r}


```

d. In Australia, phone have 10 digits - but unlike in the US where we write all numbers as “123-456-7890”, they write land lines and cell phones differently¹:  
   * Landlines: 12-3456-7890  
   * Cell phones: 1234-567-890  

There are two different phones listed for each record. Make all phone numbers written like cell phones. Show it works by printing the first 10 phone numbers of each column.  

```{r}


```

e. Produce a histogram of the log of the apartment numbers for all addresses. (You may assume any number at the end of the an address is an apartment number.)  
```{r}


```

f. [Benford’s law](https://en.wikipedia.org/wiki/Benford%27s_law) is an observation about the distribution of the leading digit of real numerical data. Examine whether the apartment numbers appear to follow Benford’s law. Do you think the apartment numbers would pass as real data?  
```{r}


```

Footnotes  

¹ Technically phone numbers starting in 04 are cell phones and all others are landlines, but we’ll ignore that detail for this problem.
```

------------------------------------------------------------------------

## GitHub Link

-   Repo: <https://github.com/brynnwoolley/STATS-506#>

------------------------------------------------------------------------
